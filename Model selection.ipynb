{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd02b47dcb8746233988d8f8505ec0b223fc8d0bd6aa34a24971bfd4da11d914854",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "\n",
    "#Algorithms\n",
    "from sklearn import ensemble, tree, svm, naive_bayes, neighbors, linear_model, gaussian_process, neural_network\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Model\n",
    "from sklearn.metrics import accuracy_score, f1_score,roc_auc_score,recall_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = '/users/yulong/desktop/yulong_year_new/all_variables.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars_data = pd.read_csv(all_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           pol_id  year  var0009  var0010  var0011  var0012  var0013  var0014  \\\n",
       "0  MWH00001004972  2016      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1  MWH00001004972  2017      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2  MWH00001004972  2018      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "3  MWH00001004972  2019      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "4  BHH00001005147  2016      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "   var0015  var0016  ...   var1089   var1090   var1091   var1092   var1093  \\\n",
       "0      NaN      NaN  ...  0.464817  0.005411  1.610939       NaN  0.014483   \n",
       "1      NaN      NaN  ...  0.951674  0.005470  3.179847  0.019704       NaN   \n",
       "2      NaN      NaN  ...  0.267688  0.005767  1.267937       NaN       NaN   \n",
       "3      NaN      NaN  ...  1.000840  0.006188  1.307391       NaN       NaN   \n",
       "4      NaN      NaN  ...  2.052881  0.002271  1.390553  0.019262  0.018343   \n",
       "\n",
       "      var1094  var1095   var1096   var1097   var1098  \n",
       "0  529.444681  16.0833       NaN  0.494665  1.875034  \n",
       "1  546.633370  14.8333  1.103489  0.933914  1.571223  \n",
       "2  550.908492  16.0834  2.230486  0.294765       NaN  \n",
       "3  564.666033  14.8333       NaN  0.980685       NaN  \n",
       "4  363.864886  58.3333  1.856222  2.134286  1.020104  \n",
       "\n",
       "[5 rows x 1281 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pol_id</th>\n      <th>year</th>\n      <th>var0009</th>\n      <th>var0010</th>\n      <th>var0011</th>\n      <th>var0012</th>\n      <th>var0013</th>\n      <th>var0014</th>\n      <th>var0015</th>\n      <th>var0016</th>\n      <th>...</th>\n      <th>var1089</th>\n      <th>var1090</th>\n      <th>var1091</th>\n      <th>var1092</th>\n      <th>var1093</th>\n      <th>var1094</th>\n      <th>var1095</th>\n      <th>var1096</th>\n      <th>var1097</th>\n      <th>var1098</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MWH00001004972</td>\n      <td>2016</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.464817</td>\n      <td>0.005411</td>\n      <td>1.610939</td>\n      <td>NaN</td>\n      <td>0.014483</td>\n      <td>529.444681</td>\n      <td>16.0833</td>\n      <td>NaN</td>\n      <td>0.494665</td>\n      <td>1.875034</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MWH00001004972</td>\n      <td>2017</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.951674</td>\n      <td>0.005470</td>\n      <td>3.179847</td>\n      <td>0.019704</td>\n      <td>NaN</td>\n      <td>546.633370</td>\n      <td>14.8333</td>\n      <td>1.103489</td>\n      <td>0.933914</td>\n      <td>1.571223</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MWH00001004972</td>\n      <td>2018</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.267688</td>\n      <td>0.005767</td>\n      <td>1.267937</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>550.908492</td>\n      <td>16.0834</td>\n      <td>2.230486</td>\n      <td>0.294765</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MWH00001004972</td>\n      <td>2019</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.000840</td>\n      <td>0.006188</td>\n      <td>1.307391</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>564.666033</td>\n      <td>14.8333</td>\n      <td>NaN</td>\n      <td>0.980685</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BHH00001005147</td>\n      <td>2016</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.052881</td>\n      <td>0.002271</td>\n      <td>1.390553</td>\n      <td>0.019262</td>\n      <td>0.018343</td>\n      <td>363.864886</td>\n      <td>58.3333</td>\n      <td>1.856222</td>\n      <td>2.134286</td>\n      <td>1.020104</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1281 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "all_vars_data.head()"
   ]
  },
  {
   "source": [
    "## Get the sorted variable importance list"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = '/users/yulong/desktop/yulong_year_new/importance_year.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_list(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data_1 = data[['Unnamed: 0.1','RF_imp','XGB_imp','DT_imp','Lasso_coe','LS_imp']]\n",
    "    data_1 = data_1.rename(columns={\"Unnamed: 0.1\":'variables'})\n",
    "    col = data_1.loc[:,'RF_imp':'LS_imp']\n",
    "    data_1['avg_imp'] = col.mean(axis=1)\n",
    "    data_1.sort_values(by=['avg_imp'],inplace=True,ascending=False )\n",
    "    var_list = list(data_1['variables'])\n",
    "    return var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ranks = var_list(imp)"
   ]
  },
  {
   "source": [
    "## get the first n variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_n_var_data(n, var_list,all_vars_path):\n",
    "    vars = var_list[:n]\n",
    "    all_vars = pd.read_csv(all_vars_path)\n",
    "    # year already in the var_list[:650], so there is no duplication\n",
    "    data = all_vars[['pol_id','year']]\n",
    "    for var in vars:\n",
    "        data[var] = all_vars[var]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-11-c9def6005573>:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[var] = all_vars[var]\n"
     ]
    }
   ],
   "source": [
    "var_650 = first_n_var_data(650,var_ranks,all_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           pol_id  year   var0415   var0447  var0465  var0590   var0686  \\\n",
       "0  MWH00001004972  2016  0.021104  0.244365     0.11      NaN       NaN   \n",
       "1  MWH00001004972  2017  0.021104  0.244365     0.11      0.0  0.000810   \n",
       "2  MWH00001004972  2018  0.021104  0.244365     0.11      0.0  0.000810   \n",
       "3  MWH00001004972  2019  0.021104  0.244365     0.11      0.0  0.000808   \n",
       "4  BHH00001005147  2016  0.047895  0.473622     0.16      NaN       NaN   \n",
       "\n",
       "    var1019  var0478  var0538  ...  var0244  var0476  var1244  var1235  \\\n",
       "0  0.013423     0.46      0.0  ...      NaN     0.62      0.0      0.0   \n",
       "1       NaN     0.46      0.0  ...      NaN     0.62      0.0      0.0   \n",
       "2       NaN     0.46      0.0  ...      NaN     0.62      0.0      0.0   \n",
       "3  0.015666     0.46      0.0  ...      NaN     0.62      0.0      0.0   \n",
       "4  0.010182     0.51      0.0  ...      NaN     0.84   3913.0   4033.0   \n",
       "\n",
       "    var1048  var0895   var0942   var0591   var1020  var0477  \n",
       "0  0.001257    777.0  0.005969       NaN  0.004397  3698.20  \n",
       "1       NaN    793.0  0.005934  0.418665  0.004016  3698.20  \n",
       "2       NaN    792.0  0.005908  0.418665  0.003832  3698.20  \n",
       "3       NaN    800.0  0.005817  0.421935  0.003772  3698.20  \n",
       "4  0.001796    334.0  0.004758       NaN  0.001507  2774.93  \n",
       "\n",
       "[5 rows x 651 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pol_id</th>\n      <th>year</th>\n      <th>var0415</th>\n      <th>var0447</th>\n      <th>var0465</th>\n      <th>var0590</th>\n      <th>var0686</th>\n      <th>var1019</th>\n      <th>var0478</th>\n      <th>var0538</th>\n      <th>...</th>\n      <th>var0244</th>\n      <th>var0476</th>\n      <th>var1244</th>\n      <th>var1235</th>\n      <th>var1048</th>\n      <th>var0895</th>\n      <th>var0942</th>\n      <th>var0591</th>\n      <th>var1020</th>\n      <th>var0477</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MWH00001004972</td>\n      <td>2016</td>\n      <td>0.021104</td>\n      <td>0.244365</td>\n      <td>0.11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.013423</td>\n      <td>0.46</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.62</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.001257</td>\n      <td>777.0</td>\n      <td>0.005969</td>\n      <td>NaN</td>\n      <td>0.004397</td>\n      <td>3698.20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MWH00001004972</td>\n      <td>2017</td>\n      <td>0.021104</td>\n      <td>0.244365</td>\n      <td>0.11</td>\n      <td>0.0</td>\n      <td>0.000810</td>\n      <td>NaN</td>\n      <td>0.46</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.62</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>793.0</td>\n      <td>0.005934</td>\n      <td>0.418665</td>\n      <td>0.004016</td>\n      <td>3698.20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MWH00001004972</td>\n      <td>2018</td>\n      <td>0.021104</td>\n      <td>0.244365</td>\n      <td>0.11</td>\n      <td>0.0</td>\n      <td>0.000810</td>\n      <td>NaN</td>\n      <td>0.46</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.62</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>792.0</td>\n      <td>0.005908</td>\n      <td>0.418665</td>\n      <td>0.003832</td>\n      <td>3698.20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MWH00001004972</td>\n      <td>2019</td>\n      <td>0.021104</td>\n      <td>0.244365</td>\n      <td>0.11</td>\n      <td>0.0</td>\n      <td>0.000808</td>\n      <td>0.015666</td>\n      <td>0.46</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.62</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>800.0</td>\n      <td>0.005817</td>\n      <td>0.421935</td>\n      <td>0.003772</td>\n      <td>3698.20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BHH00001005147</td>\n      <td>2016</td>\n      <td>0.047895</td>\n      <td>0.473622</td>\n      <td>0.16</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.010182</td>\n      <td>0.51</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.84</td>\n      <td>3913.0</td>\n      <td>4033.0</td>\n      <td>0.001796</td>\n      <td>334.0</td>\n      <td>0.004758</td>\n      <td>NaN</td>\n      <td>0.001507</td>\n      <td>2774.93</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 651 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "var_650.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_650.to_csv('year_top650_variables.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(400719, 651)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "var_650.shape"
   ]
  },
  {
   "source": [
    "## Final round data integrity checking"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_adjust(data):\n",
    "    # adjust negative outlier. \n",
    "    for column in list(data.columns)[2:]:\n",
    "        Q1 = data[column].quantile(q=0.01)\n",
    "        IQR = data[column].quantile(q=0.75) - data[column].quantile(q=0.25)\n",
    "        data[column] = data[column].apply(lambda x: Q1 if x< (Q1-1.5*IQR) else x)\n",
    "    \n",
    "    # adjust positive outlier\n",
    "    for column in list(data.columns)[2:]:\n",
    "        Q99 = data[column].quantile(q=0.99)\n",
    "        IQR = data[column].quantile(q=0.75) - data[column].quantile(q=0.25)\n",
    "        data[column] = data[column].apply(lambda x: Q99 if x> (Q99+1.5*IQR) else x)\n",
    "    \n",
    "    \n",
    "    # Get the check list\n",
    "    data1 = data.describe(percentiles=[0.5]).T\n",
    "    data2 = data1['50%']\n",
    "    data2.to_csv('variable_median_checklist.csv',index=False)\n",
    "\n",
    "    # Make the missing value indicator and fill the missing with median\n",
    "    for column in list(data.columns)[2:]:\n",
    "        data[column + '_ind'] = data[column].isnull().astype(int)\n",
    "    \n",
    "    # fillin missing value with the median\n",
    "    for column in list(data.columns)[2:]:\n",
    "        data[column].fillna(data[column].median(),inplace=True)\n",
    "    \n",
    "    data.to_csv('top_650_variables_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adjust(var_650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_650 = '/users/yulong/desktop/top_650_variables_cleaned.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv(clean_650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(400719, 1300)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "clean_data.shape"
   ]
  },
  {
   "source": [
    "## Model training "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_id = pd.read_csv('/users/yulong/desktop/yulong_year_new/sample design/id_downsample_train.csv')\n",
    "downsample_data = pd.merge(downsample_id, clean_data,on=['pol_id','year'])\n",
    "downsample_data.to_csv('downsample_training_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(alglist,X_train,X_test,y_train, y_test):\n",
    "    algorithms = pd.DataFrame()\n",
    "    idx = 0\n",
    "\n",
    "    for a in alglist:\n",
    "        a.fit(X_train, y_train)\n",
    "        pred = a.predict(X_test)\n",
    "        pred1 = a.predict(X_train)\n",
    "        acc = accuracy_score(y_test, pred) \n",
    "        f1 = f1_score(y_test, pred)\n",
    "        auc_train = roc_auc_score(y_train,pred1)\n",
    "        auc_test = roc_auc_score(y_test,pred)\n",
    "        rec =recall_score(y_test,pred)\n",
    "        \n",
    "        Alg = a.__class__.__name__\n",
    "        \n",
    "        algorithms.loc[idx, 'Algorithm'] = Alg\n",
    "        algorithms.loc[idx, 'Accuracy'] = acc\n",
    "        algorithms.loc[idx, 'F1 Score'] = f1\n",
    "        algorithms.loc[idx, 'AUC_test'] = auc_test\n",
    "        algorithms.loc[idx, 'AUC_train'] = auc_train\n",
    "        algorithms.loc[idx,'Recall'] = rec\n",
    "\n",
    "        idx+=1\n",
    "    \n",
    "    algorithms.to_csv(\"evaluation_downsample_train.csv\",index=False)"
   ]
  },
  {
   "source": [
    "## Reduction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_id = pd.read_csv('/users/yulong/desktop/yulong_year_new/sample design/id_downsample_train.csv')\n",
    "downsample_data = pd.merge(downsample_id, clean_data,on=['pol_id','year'])\n",
    "downsample_data.to_csv('downsample_training_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(42922, 1304)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "downsample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/users/yulong/desktop/yulong_year_new/sample design/id_test.csv')\n",
    "test_data = pd.merge(test, clean_data,on=['pol_id','year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('test_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_list = [\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),linear_model.LogisticRegressionCV(),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.Perceptron(),\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    xgb.XGBClassifier()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction(train, test, iter,alg_list):\n",
    "  traindf = pd.read_csv(train)\n",
    "  testdf = pd.read_csv(test)\n",
    "  # all 650 variables\n",
    "  var_list = traindf.columns.to_list()\n",
    "\n",
    "  # reduction\n",
    "  count = 0\n",
    "  while count < iter:\n",
    "    var_list = var_list[:len(var_list)//2]\n",
    "    traindf = traindf[traindf.columns.intersection(var_list)]\n",
    "    testdf = testdf[testdf.columns.intersection(var_list)]\n",
    "    y_train = traindf['no_hit']\n",
    "    X_train = traindf.drop(['no_hit','ZIP5','pol_id','STATE','year','ZIP4'], axis=1)\n",
    "    y_test = testdf['no_hit']\n",
    "    X_test = testdf.drop(['no_hit','ZIP5','pol_id','STATE','year','ZIP4'], axis=1)\n",
    "\n",
    "    # Train\n",
    "\n",
    "    col = []\n",
    "    algorithms = pd.DataFrame(columns = col)\n",
    "    idx = 0\n",
    "\n",
    "    #Train and score algorithms\n",
    "    for a in alg_list:\n",
    "      a.fit(X_train, y_train)\n",
    "      pred = a.predict(X_test)\n",
    "      pred_train = a.predict(X_train)\n",
    "      acc = accuracy_score(y_test, pred)\n",
    "      acc_train = accuracy_score(y_train, pred_train)\n",
    "      f1 = f1_score(y_test, pred)\n",
    "      f1_train = f1_score(y_train, pred_train)\n",
    "      auc = roc_auc_score(y_test, pred)\n",
    "      auc_train = roc_auc_score(y_train, pred_train)\n",
    "      recall = recall_score(y_test, pred)\n",
    "      recall_train = recall_score(y_train, pred_train)\n",
    "      Alg = a.__class__.__name__\n",
    "      algorithms.loc[idx, 'Algorithm'] = Alg\n",
    "      algorithms.loc[idx, 'Accuracy_train'] = acc_train\n",
    "      algorithms.loc[idx, 'Accuracy_test'] = acc\n",
    "      algorithms.loc[idx, 'F1 Score_train'] = f1_train\n",
    "      algorithms.loc[idx, 'F1 Score_test'] = f1\n",
    "      algorithms.loc[idx, 'AUC Score_train'] = auc_train\n",
    "      algorithms.loc[idx, 'AUC Score_test'] = auc\n",
    "      algorithms.loc[idx, 'Recall Score_train'] = recall_train\n",
    "      algorithms.loc[idx, 'Recall Score'] = recall\n",
    "      # after engineering the missing value indicator, it becomes the feature. \n",
    "      algorithms.loc[idx, 'variables'] = len(var_list)\n",
    "      idx+=1\n",
    "    algorithms.to_csv(f'year_results_{count}.csv')   \n",
    "\n",
    "# 查variable的importance\n",
    "#取variable importance的前一半\n",
    "#输出这一半\n",
    "#打他frame减半\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ..\n",
    "test = ..\n",
    "\n",
    "train(train, test) --> return metrics of all models\n",
    "\n",
    "for i in iter:\n",
    "    check_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = '/users/yulong/desktop/downsample_training_data.csv'\n",
    "test = '/users/yulong/desktop/test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ernative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[22:48:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[22:49:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[22:49:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "/Users/yulong/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[22:50:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "reduction(train, test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb22452a940>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 12, 'axes.edgecolor':'grey', 'xtick.color':'grey',\n",
    "                     'ytick.color':'grey', 'figure.facecolor':'white'})\n",
    "correlation_matrix = downsample_data.corr().round(2)\n",
    "plt.figure(figsize = (16,10))\n",
    "sns.heatmap(data=correlation_matrix, annot=True)"
   ]
  }
 ]
}